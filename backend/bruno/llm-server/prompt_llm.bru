meta {
  name: prompt_llm
  type: http
  seq: 1
}

post {
  url: {{llm_url}}/v1beta/models/gemma-3-4b-it:generateContent
  body: json
  auth: inherit
}

headers {
  Content-Type: application/json
}

body:json {
  {
    "contents": [
      {
        "parts": [
          {"text": "Yes or no: Is Python case-sensitive?"}
        ]
      }
    ],
    "generationConfig": {
      "maxOutputTokens": 100,
      "temperature": 0.7
    }
  }
}

tests {
  test("Should successfully call LLM", function() {
    expect(res.status).to.equal(200);
    expect(res.body).to.have.property('candidates');
  });
}
